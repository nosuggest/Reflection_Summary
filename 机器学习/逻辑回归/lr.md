# LR推导，基础5连问

- 伯努利过程
    - 对于lr来说事情只有发生和不发生两种可能，对于已知样本来说，满足伯努利的概率假设：
        - p(y=1/x,θ) = h(θ,x)
        - p(y=0/x,θ) = 1-h(θ,x)
        - p(y/x,θ) = h(θ,x)^y · (1-h(θ,x))^(1-y) 
            - 第i个样本正确预测的概率如上可得
    - 几率odds
        - 数据特征下属于正例及反例的比值
        - ln(y/(1-y))
- 条件概率分布
- 极大似然
- 损失函数
- 梯度下降

# LR明明是分类模型为什么叫回归？
观测样本中该特征在正负类中出现概率的比值满足线性条件，用的是线性拟合比率值，所以叫回归

# 为什么LR可以用来做CTR预估？
1. 点击行为为正向，未点击行为为负向，ctr需要得到点击行为的概率，lr可以产出正向行为的概率，完美match
2. 实现简单，方便并行，计算迭代速度很快
3. 可解释性强，可结合正则化等优化方法

# 满足什么样条件的数据用LR最好？
- 特征之间尽可能独立
    - 不独立所以我们把不独立的特征交叉了
        - 还记得FM的思路？
- 离散特征
    - 连续特征通常没有特别含义，31岁和32岁差在哪？
    - 离散特征方便交叉考虑
    - 在异常值处理上也更加方便
    - 使的lr满足分布假设
        - 什么分布假设？
- 在某种确定分类上的特征分布满足高斯分布
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wh7dd6bkj310w034gmb.jpg)
    - C1和C2为正负类，观测样本中该特征在正负类中出现概率的比值满足线性条件的前提就是P服从正太分布
        - 实际中不满足的很多，不满足我们通常就离散化，oneHotEncode

此处就用到了全概率公式推导，有可能会回到[写出全概率公式&贝叶斯公式](基础概念/先验概率和后验概率/先验概率和后验概率.md#L96)的问题中

# 我的总结：
- 逻辑回归假设观测样本中该特征在正负类中出现结果服从伯努利分布，通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的