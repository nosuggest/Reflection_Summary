# 损失函数是啥
mse,最小均方误差:![](https://tva1.sinaimg.cn/large/006y8mN6gy1g933uf4aimj305u01fa9w.jpg)

# 最小二乘/梯度下降手推
- 最小二乘
    - 损失函数：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g93458dklvj306l011t8j.jpg)
    - 求导可得：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g93489pnxxj3052014jr7.jpg)
        - 使右侧为0可得：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g934a6q83tj304300kdfm.jpg) 
        - 如果X点乘X的转置可逆则有唯一解，否则无法如此求解
- 梯度下降
    - 损失函数：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g933uf4aimj305u01fa9w.jpg)
    - 求导可得梯度：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g934mwtnodj307401fdfp.jpg)
    
# 介绍一下岭回归
加上l2的线性回归：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g934px37g4j305b017glf.jpg)

在用最小二乘推导的过程和上面一样，最后在结果上进行了平滑，保证有解：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g934t64beij304w00kmwy.jpg)
    
# 什么时候使用岭回归？
样本数少，或者样本重复程度高

# 什么时候用Lasso回归？    
特征过多，稀疏线性关系，目的为了在一堆特征里面找出主要的特征